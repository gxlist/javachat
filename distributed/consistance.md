# 分布式锁



## 分布式锁的作用是什么？

分布式系统需要解决数据一致性的问题，就会用到分布式锁。

## 一致性有几种？

强一致性，最终一致性，用户一致性。

## Lease租期机制

授权者主节点承诺在约定时间内不修改数据，从节点可以放心使用。过期后，从节点删除数据，主节点阻塞到所有从节点都过期，再更新租期数据。那么，早失效的节点就要锁定服务，影响可用性。解决方案包括：更新为没有租期的临时数据。提前主动通知失效。业务上不相关的资源，可以按照锁分离策略，解除锁定。

# 分布式事务

## 分布式事务的实现有哪些？

XA协议，提供回滚接口，本地消息表

## XA协议

两阶段提交协议(如XA)在主流的关系型数据库中广泛使用。JTA（java事务API）是符合XOpen组织的DTP(分布式事务处理)模型，该模型中TM(事务管理器)和RM(资源管理器)之间的接口就是XA协议。Tomcat没有实现JTA, 需要借助Jotm等来实现，可以由spring事务整合。部署在linux平台的mysql不支持分布式事务。

这种方法实现简单，适合传统单体应用，在同一个方法中跨库操作，对性能影响大。

## 提供回滚接口

服务化架构中一个功能需要协调多个原子服务，如果要求同步返回结果，就可以采用串行调用、失败回滚的方式。除了优先调用的回滚接口，还可以通过传参实现。

这种方法适合串行服务少、回滚简单的场景。

## 本地消息表

远程分布式事务拆分成一系列的本地事务，借助关系型数据库的表来实现。

第一步通过本地事务同步刷盘保证凭证消息插入消息表。第二步，通过高时效的MQ来通知对方，通知失败的用定时任务扫描消息表的数据，再次发送或者人工处理。消息消费者方面在消费状态表上记录消费状态，事务操作前先检查消息的消费状态，已消费则不执行，否则执行完后通过本地事务控制来更新消费状态表。（是不是也可以通过hashmap内存缓存去重+主键插入对消息去重？）

这种实现非常经典，基本上避免了分布式事务，实现了最终一致性。但是关系型数据库的吞吐量和性能不支持高并发场景下的写操作。

## 非事务消息
消息出列后，消费者端的业务要执行成功，否则消息不能丢失。消息的重复消费问题要解决。

主流的MQ产品都具有持久化消息的功能，消费失败可以重试。重复消费可以通过接口的幂等设计，以及消费日志或者状态表来实现。

这种方式比较常见，吞吐量和性能由于关系型数据库方案。

## 事务消息

除了前面的异常捕获和回滚的方式，还有RocketMQ的方法：

第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。

对于确认消息发送失败的情况，RocketMQ会定期扫描集群中的事务消息，这时候发现了prepared消息，就会想发送者确认，事务执行情况和消息处理策略。这样就保证了消息发送与本地事务同时成功或者同时失败。

目前的互联网电商几乎都是使用了类似的方法。主流的开源MQ都没有实现对事务消息的支持，RocketMQ的事务消息部分也没有开源。

## 其他补偿方式

类似于CAS的死循环重试，支付宝回调请求和一些MQ的重试补偿也是不断重试。对于成熟的系统，可用性很高，瞬时的网络故障和调用超时引起的问题，重试是很有效的解决方法。

致命异常则应记录详细的日志，并提高警戒等级，邮件通知人工处理。



## 什么是事务补偿

在事务链中的任何一个正向事务操作，都必须存在一个完全符合回滚规则的可逆事务。tcc-transaction)是基于补偿型事务的AP系统的一种实现, 具有最终一致性。

## redis怎么实现分布式锁？

multi, exec, discard, watch. 分布式事务则使用setnx 或者set nx



## 什么是2pc和3pc?

**二阶段提交**协议是一个强一致性算法，将提交过程分为2个阶段：

第一阶段：提交事务请求（投票阶段，如果参与者超时？）

1. 事务询问：协调者把事务拆分后，向参与者发送包含事务内容的请求，询问是否可以执行，并等待响应。
1. 执行事务：参与者执行事务，并把undo和redo日志写入事务日志。
1. 返回响应：参与者向协调者返回事务的执行结果。

第二阶段：执行事务提交（执行阶段）

1. 发送提交/回滚请求：协调者根据返回的执行结果，发送commit/rollback请求。
1. 事务提交：参与者执行事务提交/使用undo日志回滚，最后释放资源。
1. 反馈结果：参与者完成事务提交/回滚后，返回执行/回滚结果。
1. 完成事务：协调者收到所有参与者的ACK消息后，完成事务/中断。

二阶段提交提交的优点是：原理简单，容易实现。
缺点是：(其他参与者的)同步阻塞、(协调者的)单点问题、(网络异常或者机器崩溃导致)数据不一致、(用超时判断中断的容错机制)过于保守。

**三阶段提交**把提交事务请求阶段参与者执行事务的步骤拆分到增加的预提交阶段。

第一阶段：询问提交(CanCommit)协调者发送包含事务内容的的可行性询问请求，参与者返回评估结果(包括超时)。

第二阶段：预提交(PreCommit)协调者发送预提交/中断请求，参与者执行事务并记录日志，返回执行结果，并等待。或者中断事务，无需回滚。

第三阶段：提交(doCommit)协调者发送提交/中断请求，参与者提交/回滚事务，返回执行/回滚结果。这个阶段内，协调者因宕机或者网络故障不能按时发送提交/中断请求，参与者的容错机制是超时自动提交。（假设是提交请求？）

3PC相对于2PC的优点是通过增加预提交阶段，降低了参与者的阻塞范围，并在协调者出现单点故障后继续达成一致。缺点是第二阶段如果出现网络分区，被隔离的参与者会自动提交，使数据不一致。

## 一组进程提出一致性提案需要保证什么？

只有提出提案才会有选定，提出的提案只能选定一个，选定后提案信息公开而排除争议。

## 一致性协议的算法有那些？

paxos, raft, quorum等。



## Raft算法

Raft算法提供了和paxos算法相同的功能和性能，但算法结构不同，更容易理解和构建。

节点角色包括：领导者，选民，候选者。

算法分为2个阶段。刚启动或者领导者崩溃后，任何一个选民服务器都可以成为一个候选者，第一阶段，向选民服务器发出选举自己的请求，超过半数同意则成为领导者。第二阶段，执行领导者的任务，发布日志复制指令。

## Quorum NWR

Amazon的Dynamo云存储系统中的一致性解决方案。N:同一份数据的副本数，W:更新成功需要的副本数，R:读取数据需要的副本数。要求：W>N/2, W+R>N。保障高可用，就要求N>=3，数据不一致可以使用客户端时间戳等来解决。TFS非结构化存储系统的策略就是N=W=3，另外，节点挂掉后，复制数据块，在新节点恢复，异步cas写数据直到成功。

数据库的双写，kafka的复制，hdfs的副本，都是这样通过多机分发数据保证可靠性的，特点是没有即时刷盘，保证了高速。

## gossip流言协议

一种去中心化的集群节点的状态同步协议，解决了快速传播和状态一致的问题。实现简单，具有较高的容错性和性能。向最近的几个节点发送。

# paxos

## paxos算法是什么？

阶段一：Proposer生成提案(基于p2c的不变性)

1. Proposer选择一个新的提案编号M[n]，然后向Acceptor某个超过半数的子集成员发送Prepare请求。
1. 如果已经批准过小于M[n]的任何提案，Acceptor就返回已经批准的最大编号的提案值。并承诺不再批准编号小于M[n]的提案。

 如果响应过更大编号的请求，或者不小于当前编号的请求已批准，这个请求就可以忽略。如果响应/批准过的最大编号被预写日志持久化，就可以在节点故障或者重启时也能保证p2c的不变性。

阶段二：Acceptor批准提案

1. 如果Proposer收到了来自半数以上的Acceptor的响应结果，就可以发送[M[n],V[n]]提案的Accept请求。这里的V[n]是所有响应中编号最大的提案的值，如果半数以上的Acceptor都没有批准过任何提案，V[n]就可以任意选择。
1. Acceptor只要尚未响应过任何编号大于M[n]的Prepare请求，那么就可以接受这个M[n]的提案。

 批准的提案可以发送给特定的Learn集合，再扩散。可以通过选取主Proposer保证算法的灵活性，避免竞争Prepare请求的“死循环”。

## paxos算法的推导和证明

假设当前已经存在外部组件可以生成全局唯一的编号，用于标识提案(包括编号和值)。

paxos算法中的三种角色包括：Proposer, Acceptor和Learner。

## 推导过程

单一的Acceptor选定第一个提案，实现简单却有单点问题，所以paxos算法要求(p1):半数以上的节点是Acceptor，使集合每次增减都会至少有一个公共成员(作为革命的火种)保存上次选举结果。另外规定一个Acceptor最多只能批准一个提案，就可以保证最终只有一个提案被选定了。

在没有失败和消息丢失的情况下，只提出一个提案也可以被选出，就需要一个Acceptor必须批准第一个收到的提案。然后Acceptor可以相互多播通信，按照某规则迭代筛选，最终选定唯一提案。

不同的Proposer分别提出多个提案，是无法选定一个提案的。那么就要结合提案编号约定提案的约束条件(p2)：如果[编号M[0],值V[0]]的提案被选定了，那么编号大于M[0]的选定提案的值必须也是V[0]。满足这个条件的多个提案可以选定唯一提案。

对该约束条件前推2个充分条件：
(p2a)如果[编号M[0],值V[0]]的提案被选定了，那么编号大于M[0]，且被Acceptor批准的提案的值必须也是V[0]。

(p2b)如果[编号M[0],值V[0]]的提案被选定了，那么编号大于M[0]的提案的值都是V[0]。

## 数学归纳法证明

假设未知的更充分的约束条件可以使这个充分条件自然成立，那么这个充分条件就可以被第二数学归纳法的证明(从证明过程可以找到“未知的更充分的约束条件”的线索)，具体表述是：假设M[0]到M[n-1]的提案的值都是V[0]，证明M[n]提案的值也是V[0]。

M[0]的提案被选定是由半数以上的Acceptor批准的。提案范围扩展到M[n-1]，批准的提案也是V[0]。要扩展到M[n]，就需要保证M[n]提案的值也是V[0]。

原理上(p2c)，对于任意的M[n]和V[n]，如果[M[n],V[n]]提案被提出，那么就一定存在一个由半数以上的Acceptor组成的集合S，满足条件：S的成员没有批准过小于M[n]的提案，或者批准过的小于M[n]的最大编号提案的值也是V[n]。

在此条件下，由于批准M[n-1]的集合和批准M[n]的集合有公共成员，该公共成员批准的编号最大的提案是V[0]，那么，就可以保证M[n]提案的值也是V[0]。

这样，未知的更充分的约束条件就找到了，paxo算法对提案的生成方法就找到了。

这个原理(p2c)的不变性推导充分条件(p2b)的第二数学归纳法表述是：提案[M[0],V[0]]被选定了，对于按照上述生成方法产生的所有更大编号的提案[M[n],V[n]]，都存在V[n]=V[0]。

1. M[n]=M[0]+1时，由于提案[M[0],V[0]]已被选定，提出M[n]提案的必然前提是存在一个Acceptor的半数以上的子集S批准了小于M[n]的提案。理论上的最大编号为M[0]，而批准M[0]的Acceptor集合与S有交集，那么Proposer对V[n]的取值就会选择V[0]。
1. 第二数学归纳法假设编号从M[0]+1到M[n]-1的所有提案的值为V[0]，来证明编号M[n]提案的值也是V[0]。根据原理(p2c)，首先一定存在一个Acceptor的子集S，批准了小于M[n]的提案。那么编号M[n]提案的值只能是这个多数集S中编号小于M[n]的最大编号提案的值。如果对应的最大编号在M[0]到M[n]-1范围内，那么这个值就是V[0]了。否则如果对应的最大编号小于M[0]，由于会与批准提案[M[0],V[0]]的Acceptor有交集，那么这个值就已经是V[0]。

这个证明过程要小心。